# B√°sico (1‚Äì5)

# Instale o PyTorch e mostre a vers√£o instalada.

# Crie tensores 1D, 2D e 3D e exiba seus tamanhos e tipos de dados.

# Converta uma lista Python ou um numpy array em tensor PyTorch.

# Execute opera√ß√µes matem√°ticas b√°sicas (soma, multiplica√ß√£o, m√©dia, desvio padr√£o).

# Gere tensores aleat√≥rios com distribui√ß√£o normal e uniforme.

# üü° Intermedi√°rio (6‚Äì10)

# Crie uma fun√ß√£o que normalize um tensor entre 0 e 1.

# Use o m√≥dulo torch.nn para montar uma rede neural simples com 1 camada oculta.

# Crie um loop de treino manual (sem Trainer) usando loss.backward() e optimizer.step().

# Visualize o valor da fun√ß√£o de perda a cada √©poca.

# Salve e carregue o modelo treinado usando torch.save() e torch.load().

# üîµ Avan√ßado (11‚Äì15)

# Implemente uma rede convolucional (CNN) para classificar o dataset MNIST.

# Use torchvision.datasets e DataLoader para carregar dados em lote.

# Adicione Dropout e BatchNorm √† rede e me√ßa a melhoria no desempenho.

# Plote as curvas de loss e accuracy durante o treino.

# Compare o desempenho usando diferentes otimizadores: SGD, Adam e RMSprop.

# üî¥ S√™nior (16‚Äì25)

# Monte uma LSTM para prever uma s√©rie temporal (ex.: dados de vendas).

# Crie uma rede de autoencoder para reduzir dimensionalidade de dados.

# Treine uma GAN (Generative Adversarial Network) simples que gere imagens artificiais.

# Use transfer learning com ResNet18 para classificar novas imagens.

# Implemente um callback personalizado que salve checkpoints autom√°ticos.

# Compare resultados com e sem GPU (use device = torch.device("cuda" if torch.cuda.is_available() else "cpu")).

# Aplique quantiza√ß√£o para reduzir tamanho do modelo e medir a diferen√ßa de desempenho.

# Integre o modelo PyTorch com ONNX e exporte-o.

# Use PyTorch Lightning para reescrever o treino de forma mais limpa e modular.

# Implemente um modelo multitarefa que preveja duas sa√≠das diferentes ao mesmo tempo.